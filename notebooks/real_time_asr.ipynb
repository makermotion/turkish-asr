{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('data-science')",
   "metadata": {
    "interpreter": {
     "hash": "351adceb4366b56d1ea9218106d4cf6e2e051aea3a6f3c7a47e972a2d8291b0b"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/scutum/envs/data-science/lib/python3.8/site-packages/torchaudio/backend/utils.py:53: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import librosa\n",
    "import numpy as np\n",
    "import speech_recognition as sr\n",
    "from transformers import Wav2Vec2CTCTokenizer, Wav2Vec2Processor, Wav2Vec2FeatureExtractor, Wav2Vec2ForCTC\n",
    "import miniaudio\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/home/scutum/wav2vec2-large-xlsr-turkish-demo/checkpoint-13000'\n",
    "processor_path = '/home/scutum/wav2vec2-large-xlsr-turkish-demo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model = Wav2Vec2ForCTC.from_pretrained(model_path).to(\"cuda\")\n",
    "else:\n",
    "    model = Wav2Vec2ForCTC.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "processor = Wav2Vec2Processor.from_pretrained(processor_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "decoded audio type: <class 'torch.Tensor'>\n",
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function.Failing to do so can result in silent errors that might be hard to debug.\n",
      "sa (sample_audio): [ -5.7529416 -10.926594   -1.822781  ...   3.799       9.60294\n",
      "   0.       ], shape (547991,)\n",
      "\n",
      "Processing...\n",
      "\n",
      "Predicting...\n",
      "Prediction\n",
      "tensor([39, 39, 39,  ..., 39, 39, 39], device='cuda:0')\n",
      "My Model: pevet büyük adan bir kahramandır bir yıldırımdır ama halk kitlesi nekil tabakası nede zamaniyiğını değildir oyıldırımı meydana getiren milletin kendisidir blut kümesi elleklerik oluşturduğunda yıldırım da kendiliğinden oluşur eğer bulutlar elekterikle yüklüde ilkse hiçbir zaman şimşek ve ya yıldırın oluşmaz yalnızca bulut yaninemli bir bu haralinde kalır milletler de böyledir eğer bir millet büyüklük ve kahramanlık özellikleni taşıyorsa ondan yıldırımlar duar kahramanlar çıkar eğer halk kitlesi nemli bir bu har yınından ibaretse hiçbirgüç ondan yıldırım çıkaramaz\n",
      "time passed: 2.3128819465637207\n",
      "decoded audio type: <class 'torch.Tensor'>\n",
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function.Failing to do so can result in silent errors that might be hard to debug.\n",
      "sa (sample_audio): [ 3.9665468  6.77062    6.509044  ... 25.025993  24.725988   0.       ], shape (571397,)\n",
      "\n",
      "Processing...\n",
      "\n",
      "Predicting...\n",
      "Prediction\n",
      "tensor([39, 39, 39,  ..., 39, 39, 39], device='cuda:0')\n",
      "My Model: bu ilki görüş ilk bakışta bir birinezıt gibi görünüyor bunlardan birini seçmek gerekiyor karlail m hakladır tostoymu ancak karlailayle tostoyun görüşleri arasındaki bu çelişki yüz eysel dir gerçekte karlail le tostoy birbirlerine karşı değillerdir ikisi birbini tamamlamaktadır burada ekisinden birini seçmek gerekmez bunlara karlailı ö tostoy denlelidir karlail da tostoyda haklıdır tıpkı paranın iki yüz igibi her görüş gerçeğin diğer yarsıdır kahraman halkı heyecanlandırı ve alevlendirir ancak onu milletinden aldığı ateş ve heyecanlaya kar\n",
      "time passed: 0.9953160285949707\n",
      "decoded audio type: <class 'torch.Tensor'>\n",
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function.Failing to do so can result in silent errors that might be hard to debug.\n",
      "sa (sample_audio): [ 2.8852985 10.0028105  3.039024  ...  7.5235724 -2.2667108  0.       ], shape (325823,)\n",
      "\n",
      "Processing...\n",
      "\n",
      "Predicting...\n",
      "Prediction\n",
      "tensor([39, 39, 39,  ..., 39, 39, 39], device='cuda:0')\n",
      "My Model: örneğin bir merciyi eli alalım geniş bir alanadağılmış olan güneş ışığına bir noktada toplama özelliğine sahiptir milyonlarca güneş ışığının bir yere toplanması la parlak bir nokto olucur bu güçlü enerjik nokta kağıt zaman gibi yanıcı maddeleri ağnında totuşturur taşı camı ve demiri kızgın hale getirir\n",
      "time passed: 0.5800271034240723\n",
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function.Failing to do so can result in silent errors that might be hard to debug.\n",
      "decoded audio type: <class 'torch.Tensor'>\n",
      "sa (sample_audio): [13.5704365 10.394069   2.859243  ... 34.366817  28.62561    0.       ], shape (28236,)\n",
      "\n",
      "Processing...\n",
      "\n",
      "Predicting...\n",
      "Prediction\n",
      "tensor([39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39,\n",
      "        39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39,\n",
      "        39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39,\n",
      "        39, 39, 39, 39, 39, 39, 39, 16, 39, 39, 39, 39, 39, 39, 39, 36, 39, 39,\n",
      "        24, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39],\n",
      "       device='cuda:0')\n",
      "My Model: ak\n",
      "time passed: 0.07727885246276855\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f9afd8c2d27e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMicrophone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlisten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/data-science/lib/python3.8/site-packages/speech_recognition/__init__.py\u001b[0m in \u001b[0;36mlisten\u001b[0;34m(self, source, timeout, phrase_time_limit, snowboy_configuration)\u001b[0m\n\u001b[1;32m    618\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mWaitTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"listening timed out while waiting for phrase to start\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m                     \u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCHUNK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m  \u001b[0;31m# reached end of the stream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m                     \u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/data-science/lib/python3.8/site-packages/speech_recognition/__init__.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyaudio_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception_on_overflow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/data-science/lib/python3.8/site-packages/pyaudio.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[1;32m    606\u001b[0m                           paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception_on_overflow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_read_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "r = sr.Recognizer()\n",
    "r.dynamic_energy_threshold = False\n",
    "r.energy_threshold = 100\n",
    "while True:\n",
    "    with sr.Microphone() as source:\n",
    "        audio = r.listen(source)\n",
    "        try:\n",
    "            start = time()\n",
    "#           print(f'Google: {r.recognize_google(audio, language=\"tr-TR\").lower()}')\n",
    "            rd = audio.get_segment()\n",
    "            rd = rd.get_wav_data()\n",
    "            da = miniaudio.decode(rd, nchannels=1)\n",
    "            decoded_audio = torch.FloatTensor(da.samples)\n",
    "            print(f'decoded audio type: {type(decoded_audio)}')\n",
    "            sa = librosa.resample(np.asarray(decoded_audio.reshape(-1)), 44_100, 16_000)\n",
    "            print(f'sa (sample_audio): {sa}, shape {sa.shape}')\n",
    "            print(f'\\nProcessing...')\n",
    "            with torch.no_grad():\n",
    "                sa = processor(sa, return_tensors='pt', padding=True)\n",
    "                print(f'\\nPredicting...')\n",
    "                if torch.cuda.is_available():\n",
    "                    logits = model(sa.input_values.to(\"cuda\")).logits\n",
    "                else:\n",
    "                    logits = model(sa.input_values).logits\n",
    "                print(f'Prediction')\n",
    "                pred_ids = torch.argmax(logits, dim=-1)[0]\n",
    "            end = time()\n",
    "            print(pred_ids)\n",
    "            print(f'My Model: {processor.decode(pred_ids)}')\n",
    "            print(f'time passed: {end - start}')\n",
    "            torch.cuda.empty_cache()\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}